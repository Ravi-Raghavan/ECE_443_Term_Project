{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# William Ching\n",
    "# Amazon Reviews Notebook\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preamble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional code cell when using Google Colab with Google Drive\n",
    "\n",
    "# remove the docstring comment block below in order to mount Google Drive\n",
    "'''\n",
    "# mount Google Drive in Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# change directory using the magic command %cd\n",
    "### replace [MY PATH] below with your own path in Google Drive ###\n",
    "### %cd /content/drive/My\\ Drive/[MY PATH] ###\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as sps\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display, Latex\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "The Amazon Reviews in Different Languages Dataset from Multilingual Amazon Reviews Corpus, provides text reviews / ratings in .json format in different languages: English, Japanese, German, French, Chinese, and Spanish (6 collections of json data). The reviews and ratings were collected from 2015 to 2019 from products sold on Amazon. For each language there are a total of 200,000 reviews in the training set (1.2 million reviews total). The ratings are balanced among all languages collections. Each record in the dataset has the following independent variables: review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. â€˜booksâ€™, â€˜appliancesâ€™, etc.). The dataset is separated into distinct json files according to the language of the review. The labels for each review is given in the name of each json file.\n",
    "\n",
    "**Task for this Dataset:**\n",
    "\n",
    "The task for this dataset will be a classification task. With this dataset we are attempting to create a machine learning model to accurately classify the language of texts from Amazon product reviews: English, Japanese, German, French, Chinese, and Spanish.\n",
    "\n",
    "**Type of Machine Learning Problem:**\n",
    "\n",
    "This problem is a supervised machine learning problem because the labels are provided in the dataset (language of data samples: 6 total). The labels are provided in the respective json file name (i.e. English reviews are provided in the json file with â€œenâ€ in file name).\n",
    "\n",
    "**Motivation:**\n",
    "\n",
    "Increasingly, people are transitioning to online markets, like Amazon, as it becomes easier to place orders and purchase items over the internet. Amazon has been around since 1994 and has since then grown to millions of users around the world and has become a prominent global business. Amazon extended their marketplace to many regions where customers speak different languages. The language of a marketplace does not necessarily always match the language of a review placed by customers. In this project, we are going to try and create a machine learning model to classify the language of each text review: English, Japanese, German, French, Chinese, and Spanish. In essence, we are trying to create a model that can detect the language of texts. Such machine learning model can help break the language barrier between buyers and sellers. I find the concept of Languages and linguistics interesting because they are an integral part of humanity. Languages enable us to share ideas, thoughts and feelings. Every language has its unique rules and syntax, but they allow humans to communicate and express themselves in different ways. Understanding different languages is important for businesses to build connections and grow a network. This project gives us an opportunity to create a machine learning system by using methods learned in class to classify language of texts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Folder Structure:**\n",
    "```\n",
    "ğŸ“‚AmazonReviews\n",
    " â”£ ğŸ“™AmazonReviews.ipynb\n",
    " â”£ ğŸ“‚Data\n",
    "    â”£ ğŸ“‚Test\n",
    "    â”ƒ  â”£ ğŸ“ dataset_de_test.json\n",
    "    â”ƒ  â”£ ğŸ“ dataset_en_test.json\n",
    "    â”ƒ  â”£ ğŸ“ dataset_es_test.json\n",
    "    â”ƒ  â”£ ğŸ“ dataset_fr_test.json\n",
    "    â”ƒ  â”£ ğŸ“ dataset_ja_test.json\n",
    "    â”ƒ  â”— ğŸ“ dataset_zh_test.json\n",
    "    â”£ ğŸ“‚Train\n",
    "       â”£ ğŸ“ dataset_de_train.json\n",
    "       â”£ ğŸ“ dataset_en_train.json\n",
    "       â”£ ğŸ“ dataset_es_train.json\n",
    "       â”£ ğŸ“ dataset_fr_train.json\n",
    "       â”£ ğŸ“ dataset_ja_train.json\n",
    "       â”— ğŸ“ dataset_zh_train.json\n",
    " ```\n",
    " #### **Dataset link:**\n",
    " https://s3.console.aws.amazon.com/s3/buckets/amazon-reviews-ml/?region=us-west-2&tab=objects\n",
    " #### **Kernel:**\n",
    " base Python 3.9.12 Conda env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Brief Exploration of Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be carry out a brief exploration of our dataset. We must first note that the training data is given in 6 .json file (see folder structure) for each respective langauges: German (de), English (en), Spanish (es), French (fr), Japanese (ja), and Chinese (zh). In order to start any exploration, we must first parse the json data into our python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_reviews = []\n",
    "de_reviews = []\n",
    "es_reviews = []\n",
    "fr_reviews = []\n",
    "ja_reviews = []\n",
    "zh_reviews = []\n",
    "for line in open('Data/Train/dataset_de_train.json', 'r'):\n",
    "    de_reviews.append(json.loads(line))\n",
    "for line in open('Data/Train/dataset_en_train.json', 'r'):\n",
    "    en_reviews.append(json.loads(line))\n",
    "for line in open('Data/Train/dataset_es_train.json', 'r'):\n",
    "    es_reviews.append(json.loads(line))\n",
    "for line in open('Data/Train/dataset_fr_train.json', 'r'):\n",
    "    fr_reviews.append(json.loads(line))\n",
    "for line in open('Data/Train/dataset_ja_train.json', 'r'):\n",
    "    ja_reviews.append(json.loads(line))\n",
    "for line in open('Data/Train/dataset_zh_train.json', 'r'):\n",
    "    zh_reviews.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have parsed the json data into python lists (en_reviews, de_reviews, es_reviews, fr_reviews, ja_reviews, and zh_reviews) we can now begin our dataset exploration. One of the first details to observe is a sample format / structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_reviews:  {'review_id': 'de_0203609', 'product_id': 'product_de_0865382', 'reviewer_id': 'reviewer_de_0267719', 'stars': '1', 'review_body': 'Armband ist leider nach 1 Jahr kaputt gegangen', 'review_title': 'Leider nach 1 Jahr kaputt', 'language': 'de', 'product_category': 'sports'} \n",
      "\n",
      "en_reviews:  {'review_id': 'en_0964290', 'product_id': 'product_en_0740675', 'reviewer_id': 'reviewer_en_0342986', 'stars': '1', 'review_body': \"Arrived broken. Manufacturer defect. Two of the legs of the base were not completely formed, so there was no way to insert the casters. I unpackaged the entire chair and hardware before noticing this. So, I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review of part of a chair I never got to sit in. I will go so far as to include a picture of what their injection molding and quality assurance process missed though. I will be hesitant to buy again. It makes me wonder if there aren't missing structures and supports that don't impede the assembly process.\", 'review_title': \"I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review ...\", 'language': 'en', 'product_category': 'furniture'} \n",
      "\n",
      "es_reviews:  {'review_id': 'es_0491108', 'product_id': 'product_es_0296024', 'reviewer_id': 'reviewer_es_0999081', 'stars': '1', 'review_body': 'Nada bueno se me fue ka pantalla en menos de 8 meses y no he recibido respuesta del fabricante', 'review_title': 'television Nevir', 'language': 'es', 'product_category': 'electronics'} \n",
      "\n",
      "fr_reviews:  {'review_id': 'fr_0424335', 'product_id': 'product_fr_0297678', 'reviewer_id': 'reviewer_fr_0961886', 'stars': '1', 'review_body': \"A dÃ©conseiller - Article n'a fonctionnÃ© qu'une fois - Je ne recommande pas du tout ce produit - Je l'ai jetÃ© ...\", 'review_title': 'Brumisateur Ã  pompe', 'language': 'fr', 'product_category': 'beauty'} \n",
      "\n",
      "ja_reviews:  {'review_id': 'ja_0388536', 'product_id': 'product_ja_0270003', 'reviewer_id': 'reviewer_ja_0454098', 'stars': '1', 'review_body': 'æ™®æ®µä½¿ã„ã¨ãƒã‚¤ã‚¯ã«ä¹—ã‚‹ã¨ãã®ãƒ–ãƒ¼ãƒ„å…¼ç”¨ã¨ã—ã¦è³¼å…¥ã—ã¾ã—ãŸã€‚è¦‹ãŸç›®ã‚„å±¥ãå¿ƒåœ°ã¯è‰¯ã„ã§ã™ã€‚ ã—ã‹ã—ã€ï¼’ãƒ¶æœˆå±¥ã„ãŸã‚‰ã‚´ãƒ åº•ãŒå‰Šã‚Œã¦ç„¡ããªã‚Šã¾ã—ãŸã€‚ã¾ãŸã€ãƒã‚¤ã‚¯ã®ã‚·ãƒ•ãƒˆãƒšãƒ€ãƒ«ã¨ã®æ‘©æ“¦ã§è¡¨çš®ãŒå‰¥ãŒã‚Œã€æœ¬é©ã§ãªã„ã“ã¨ãŒéœ²å‘ˆã—ã¾ã—ãŸã€‚ã¡ãªã¿ã«é˜²æ°´ã¨ã‚‚æ›¸ã„ã¦ã„ã¾ã™ãŒã€é›¨ã®æ—¥ã¯å†…éƒ¨ã«æ°´ãŒæŸ“ã¿ã¾ã™ã€‚ å®‰ãã¦è¦‹ãŸç›®ã‚‚è‰¯ãã€å±¥ãã‚„ã™ã‹ã£ãŸã®ã§ã™ãŒã€è€ä¹…æ€§ã®ãªã•ã€æœ¬é©ã§ã‚‚é˜²æ°´ã§ã‚‚ç„¡ã‹ã£ãŸã“ã¨ãŒæ®‹å¿µã§ã™ã€‚çµå±€ã€æœ¬é©ã®é˜²æ°´ãƒ–ãƒ¼ãƒ„ã‚’è²·ã„ç›´ã—ã¾ã—ãŸã€‚', 'review_title': 'æœ¬é©ã§ã‚‚é˜²æ°´ã§ã‚‚ãªã„', 'language': 'ja', 'product_category': 'shoes'} \n",
      "\n",
      "zh_reviews:  {'review_id': 'zh_0626061', 'product_id': 'product_zh_0691762', 'reviewer_id': 'reviewer_zh_0824776', 'stars': '1', 'review_body': 'æœ¬äººè´¦å·è¢«ç›—ï¼Œèµ„é‡‘è¢«æ±Ÿè¥¿ï¼ˆæ¨å»ºï¼‰æŒªç”¨ï¼Œè¯·äºšé©¬é€Šå°½å¿«æŸ¥å®ï¼Œå°†æœ¬äººçš„200å…ƒèµ„é‡‘é€€å›ã€‚æœ¬äººå·²äº2017å¹´11æœˆ30æ—¥æäº¤é€€è´§ç”³è¯·ï¼Œä¸ºä½•åˆ°2018å¹´äº†è¿˜æ˜¯æ²¡è§£å†³ï¼Ÿäºšé©¬é€Šæ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿè¯·ç»™æœ¬äººä¸€ä¸ªåˆç†è§£é‡Šã€‚', 'review_title': 'æ­¤ä¹¦ä¸æ˜¯æœ¬äººè´­ä¹°', 'language': 'zh', 'product_category': 'book'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample review data:\n",
    "print(\"de_reviews: \",de_reviews[0], \"\\n\")\n",
    "print(\"en_reviews: \",en_reviews[0], \"\\n\")\n",
    "print(\"es_reviews: \",es_reviews[0], \"\\n\")\n",
    "print(\"fr_reviews: \",fr_reviews[0], \"\\n\")\n",
    "print(\"ja_reviews: \",ja_reviews[0], \"\\n\")\n",
    "print(\"zh_reviews: \",zh_reviews[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that each reviews python list contains a list of python dict or objects. We can extract the raw features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Features:  ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category']\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Features: \", list(de_reviews[0].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each json object have teh following fields / raw features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can take a look at the size of each reviews python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_reviews size:  200000 reviews\n",
      "\n",
      "en_reviews size:  200000 reviews\n",
      "\n",
      "es_reviews size:  200000 reviews\n",
      "\n",
      "fr_reviews size:  200000 reviews\n",
      "\n",
      "ja_reviews size:  200000 reviews\n",
      "\n",
      "zh_reviews size:  200000 reviews\n",
      "\n",
      "Total number of training samples:  1200000 reviews\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring size of data\n",
    "print(\"de_reviews size: \",len(de_reviews), \"reviews\\n\")\n",
    "print(\"en_reviews size: \",len(en_reviews), \"reviews\\n\")\n",
    "print(\"es_reviews size: \",len(es_reviews), \"reviews\\n\")\n",
    "print(\"fr_reviews size: \",len(fr_reviews), \"reviews\\n\")\n",
    "print(\"ja_reviews size: \",len(ja_reviews), \"reviews\\n\")\n",
    "print(\"zh_reviews size: \",len(zh_reviews), \"reviews\\n\")\n",
    "\n",
    "print(\"Total number of training samples: \", len(de_reviews) + len(en_reviews) + len(es_reviews) + len(fr_reviews) + len(ja_reviews) + len(zh_reviews), \"reviews\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are a total of 1.2 million reivews with 200,000 reviews from each lanaguage .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Feature Extraction / Feature Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Comparative Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Discussion of Ethical Issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Bibliography**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
